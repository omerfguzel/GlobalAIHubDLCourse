{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iq1zkjoZibAG",
        "CB8nJBhFibBd"
      ]
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K64BL-JSibBT"
      },
      "source": [
        "# Design Choices in Recurrent Neural Networks\r\n",
        "# **Ömer Faruk Güzel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qizsy1_ia__"
      },
      "source": [
        "###  Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SQQBH6fFibAA"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.datasets import imdb\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import timeit\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq1zkjoZibAG"
      },
      "source": [
        "### Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4HAT-LWqibAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6afffb-dbe1-49aa-8c00-357540dc4f4a"
      },
      "source": [
        "max_features = 1000\n",
        "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
        "batch_size = 32\n",
        "\n",
        "# save np.load\n",
        "#np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "#np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "#np.load = np_load_old\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45x9V7tSibBT"
      },
      "source": [
        "## Part 1: Influence of number of nodes\r\n",
        "\r\n",
        "Try the models with different number of nodes such as 32, 64, 128 etc.\r\n",
        "\r\n",
        "Analyze the number of model parameters, accuracy and training time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYmu59jHibBU"
      },
      "source": [
        "### LSTM with 8 nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xBy67aRQibBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8986162f-d5ce-4377-f36c-3700f51178c9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 8))\n",
        "model.add(LSTM(8, dropout=0.0, recurrent_dropout=0.0))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "start = timeit.default_timer()\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 8)           8000      \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 8)                 544       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 8,553\n",
            "Trainable params: 8,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.6007 - accuracy: 0.6566 - val_loss: 0.4143 - val_accuracy: 0.8130\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4143 - accuracy: 0.8130\n",
            "Test score: 0.4142504632472992\n",
            "Test accuracy: 0.8130000233650208\n",
            "Time Taken to run the model: 8.500383197999781 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9ZD__ogibBb"
      },
      "source": [
        "### LSTM with 16 nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "C5CNadYribBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d08c967-86ff-4ffa-e565-ddea9c9e0712"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 8))\n",
        "model.add(LSTM(16, dropout=0.0, recurrent_dropout=0.0))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "start = timeit.default_timer()\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 8)           8000      \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 16)                1600      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 9,617\n",
            "Trainable params: 9,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.5786 - accuracy: 0.6704 - val_loss: 0.4085 - val_accuracy: 0.8133\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4085 - accuracy: 0.8133\n",
            "Test score: 0.4084605872631073\n",
            "Test accuracy: 0.8132799863815308\n",
            "Time Taken to run the model: 8.538254277000078 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtWxrXlSqz_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25120a45-ad22-408c-e5be-e651a626e6e0"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(max_features, 8))\r\n",
        "model.add(LSTM(128, dropout=0.0, recurrent_dropout=0.0))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "start = timeit.default_timer()\r\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\r\n",
        "end = timeit.default_timer()\r\n",
        "\r\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\r\n",
        "print('Test score:', score)\r\n",
        "print('Test accuracy:', acc)\r\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 8)           8000      \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 128)               70144     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 78,273\n",
            "Trainable params: 78,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 9s 10ms/step - loss: 0.5851 - accuracy: 0.6642 - val_loss: 0.4153 - val_accuracy: 0.8080\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 0.4153 - accuracy: 0.8080\n",
            "Test score: 0.41530758142471313\n",
            "Test accuracy: 0.8080400228500366\n",
            "Time Taken to run the model: 9.315172520000033 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFur07amrA4Z"
      },
      "source": [
        "### Write your findings about number of nodes here?\r\n",
        "\r\n",
        "1.   Finding 1\r\n",
        "2.   Finding 2\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB8nJBhFibBd"
      },
      "source": [
        "## Part 2: Influence of Embedding\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rRHQ89RiibBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "affa1f15-5558-4d73-b60a-5e86793f58b9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 4))\n",
        "model.add(LSTM(16, dropout=0.0, recurrent_dropout=0.0))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "start = timeit.default_timer()\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, None, 4)           4000      \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 16)                1344      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 5,361\n",
            "Trainable params: 5,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.6024 - accuracy: 0.6489 - val_loss: 0.4211 - val_accuracy: 0.8105\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 0.4211 - accuracy: 0.8105\n",
            "Test score: 0.42111504077911377\n",
            "Test accuracy: 0.810479998588562\n",
            "Time Taken to run the model: 8.39360831399972 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI5WWTvbr6vV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d2985e-f91a-4b6a-af8d-e88ee486136d"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(max_features, 64))\r\n",
        "model.add(LSTM(16, dropout=0.0, recurrent_dropout=0.0))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "start = timeit.default_timer()\r\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\r\n",
        "end = timeit.default_timer()\r\n",
        "\r\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\r\n",
        "print('Test score:', score)\r\n",
        "print('Test accuracy:', acc)\r\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 16)                5184      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 69,201\n",
            "Trainable params: 69,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 10s 10ms/step - loss: 0.5501 - accuracy: 0.7055 - val_loss: 0.3958 - val_accuracy: 0.8168\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.3958 - accuracy: 0.8168\n",
            "Test score: 0.39583641290664673\n",
            "Test accuracy: 0.8168399930000305\n",
            "Time Taken to run the model: 9.576857149999796 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVnNJ6Q7r8OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4ca636-6e7e-44bf-c987-b71a4139527a"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(max_features, 256))\r\n",
        "model.add(LSTM(16, dropout=0.0, recurrent_dropout=0.0))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "start = timeit.default_timer()\r\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\r\n",
        "end = timeit.default_timer()\r\n",
        "\r\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\r\n",
        "print('Test score:', score)\r\n",
        "print('Test accuracy:', acc)\r\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, None, 256)         256000    \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 16)                17472     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 273,489\n",
            "Trainable params: 273,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 12s 14ms/step - loss: 0.5418 - accuracy: 0.7141 - val_loss: 0.3923 - val_accuracy: 0.8210\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3923 - accuracy: 0.8210\n",
            "Test score: 0.39228808879852295\n",
            "Test accuracy: 0.8209599852561951\n",
            "Time Taken to run the model: 12.151193093000074 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukAmcE5qu89O",
        "outputId": "9e627439-18d4-402d-a94f-ec657aa7dbef"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(max_features, 512))\r\n",
        "model.add(LSTM(16, dropout=0.0, recurrent_dropout=0.0))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "start = timeit.default_timer()\r\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\r\n",
        "end = timeit.default_timer()\r\n",
        "\r\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\r\n",
        "print('Test score:', score)\r\n",
        "print('Test accuracy:', acc)\r\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, None, 512)         512000    \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 16)                33856     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 545,873\n",
            "Trainable params: 545,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 15s 18ms/step - loss: 0.5545 - accuracy: 0.6958 - val_loss: 0.4035 - val_accuracy: 0.8180\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8180\n",
            "Test score: 0.40349820256233215\n",
            "Test accuracy: 0.8180400133132935\n",
            "Time Taken to run the model: 15.398136687999795 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMqv2Kf1r3VP"
      },
      "source": [
        "### Write your findings about number of embedding features here?\r\n",
        "\r\n",
        "1.   Increasing the number of embedding features leads longer training time, higher number of trainable parameters as expected.\r\n",
        "2.   But the increase of that feature number leads both increase and decrease in accuracy. I tried 4, 64, 256 and 512 features. I realized that 256 features can be considered as treshold for the number of embedding features. I got highest accuracy with 256 and when I keep increasing, accuracy started decreasing.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ENmvb0BibBi"
      },
      "source": [
        "## Part 3: Influence of Dropout\r\n",
        "\r\n",
        "Try the models with different rates of dropout from 0 to 1\r\n",
        "\r\n",
        "Analyze the number of model parameters, accuracy and training time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXpsYJzNibBj"
      },
      "source": [
        "### Dropout with rate 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pBQ4317BibBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9eabb4-d480-45ef-bba2-a78eb4dbed20"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(8, dropout=0.5, recurrent_dropout=0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "start = timeit.default_timer()\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_26 (Embedding)     (None, None, 32)          32000     \n",
            "_________________________________________________________________\n",
            "lstm_31 (LSTM)               (None, 8)                 1312      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 33,321\n",
            "Trainable params: 33,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 238s 301ms/step - loss: 0.6042 - accuracy: 0.6611 - val_loss: 0.4276 - val_accuracy: 0.8058\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.4276 - accuracy: 0.8058\n",
            "Test score: 0.4276007413864136\n",
            "Test accuracy: 0.8057600259780884\n",
            "Time Taken to run the model: 237.63186271500035 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rEHxPCN7ibBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b6f5ae-6eca-4d35-feac-e18249533bd4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(8, dropout=0.1, recurrent_dropout=0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "start = timeit.default_timer()\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_27 (Embedding)     (None, None, 32)          32000     \n",
            "_________________________________________________________________\n",
            "lstm_32 (LSTM)               (None, 8)                 1312      \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 33,321\n",
            "Trainable params: 33,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 238s 302ms/step - loss: 0.5813 - accuracy: 0.6901 - val_loss: 0.4210 - val_accuracy: 0.8082\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.4210 - accuracy: 0.8082\n",
            "Test score: 0.42101287841796875\n",
            "Test accuracy: 0.8082399964332581\n",
            "Time Taken to run the model: 238.04765940500056 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--A0IdGbsAa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee52a51-6760-4154-85dc-ecd94b4bde02"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(max_features, 32))\r\n",
        "model.add(LSTM(8, dropout=0.9, recurrent_dropout=0.5))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "start = timeit.default_timer()\r\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\r\n",
        "end = timeit.default_timer()\r\n",
        "\r\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\r\n",
        "print('Test score:', score)\r\n",
        "print('Test accuracy:', acc)\r\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_28 (Embedding)     (None, None, 32)          32000     \n",
            "_________________________________________________________________\n",
            "lstm_33 (LSTM)               (None, 8)                 1312      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 33,321\n",
            "Trainable params: 33,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 237s 300ms/step - loss: 0.6669 - accuracy: 0.5668 - val_loss: 0.4894 - val_accuracy: 0.7652\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.4894 - accuracy: 0.7652\n",
            "Test score: 0.48935937881469727\n",
            "Test accuracy: 0.7652400135993958\n",
            "Time Taken to run the model: 237.34768932099996 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK0QJhngsH_t"
      },
      "source": [
        "### Write your findings about influence of dropout rate here?\r\n",
        "\r\n",
        "1.   The training time remains nearly same with the change of dropout rate. It didn't effect number of trainable parameters as expected.\r\n",
        "2.   The accuracy is slightly increased when I tune dropout ratio 0.5 to 0.1. But decreased clearly in 0.9.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZu33HjEibBq"
      },
      "source": [
        "## Part 4: Multilayered RNNs\r\n",
        "\r\n",
        "Try the models with different number of layers from smaller to larger.\r\n",
        "\r\n",
        "Analyze the number of model parameters, accuracy and training time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T26reJlTibBq"
      },
      "source": [
        "### RNN with 2 layer LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LScH30z1ibBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4accbb00-d2ce-4919-abbd-1b9ada3678c4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 8))\n",
        "model.add(LSTM(8, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
        "model.add(LSTM(8, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
        "model.add(LSTM(8, dropout=0.0, recurrent_dropout=0.0))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "start = timeit.default_timer()\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_29 (Embedding)     (None, None, 8)           8000      \n",
            "_________________________________________________________________\n",
            "lstm_34 (LSTM)               (None, None, 8)           544       \n",
            "_________________________________________________________________\n",
            "lstm_35 (LSTM)               (None, None, 8)           544       \n",
            "_________________________________________________________________\n",
            "lstm_36 (LSTM)               (None, 8)                 544       \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 9,641\n",
            "Trainable params: 9,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 18s 18ms/step - loss: 0.5881 - accuracy: 0.6554 - val_loss: 0.4197 - val_accuracy: 0.8074\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.4197 - accuracy: 0.8074\n",
            "Test score: 0.4197038412094116\n",
            "Test accuracy: 0.8073599934577942\n",
            "Time Taken to run the model: 17.71710273700046 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dcVD_Q-ibBt"
      },
      "source": [
        "### RNN with 3 layer LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "27GyLcMTibBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b20939f-c4fd-403d-fa26-0fa564ef5db9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 8))\n",
        "model.add(LSTM(8, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
        "model.add(LSTM(8, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
        "model.add(LSTM(8, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
        "model.add(LSTM(8, dropout=0.0, recurrent_dropout=0.0))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "start = timeit.default_timer()\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_30 (Embedding)     (None, None, 8)           8000      \n",
            "_________________________________________________________________\n",
            "lstm_37 (LSTM)               (None, None, 8)           544       \n",
            "_________________________________________________________________\n",
            "lstm_38 (LSTM)               (None, None, 8)           544       \n",
            "_________________________________________________________________\n",
            "lstm_39 (LSTM)               (None, None, 8)           544       \n",
            "_________________________________________________________________\n",
            "lstm_40 (LSTM)               (None, 8)                 544       \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 10,185\n",
            "Trainable params: 10,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 22s 22ms/step - loss: 0.6088 - accuracy: 0.6415 - val_loss: 0.4353 - val_accuracy: 0.8011\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4353 - accuracy: 0.8011\n",
            "Test score: 0.435276061296463\n",
            "Test accuracy: 0.8010799884796143\n",
            "Time Taken to run the model: 21.972712487000535 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjD_fTTCibBx"
      },
      "source": [
        "### Write your findings about number of layers here?\r\n",
        "\r\n",
        "1.   It took longer 4 more seconds to train when I increased the number of LSTM layers. But the number of trainable parameters is increased.\r\n",
        "2.   The accuracy is slightly decreased when I add 1 more LSTM layer.\r\n"
      ]
    }
  ]
}