{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "Project_Image_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNci3SsyOvpk"
      },
      "source": [
        "# Project - Image Classification\r\n",
        "# **Ömer Faruk Güzel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oGkFF4WOxAD"
      },
      "source": [
        "Hola !\n",
        "\n",
        "Objective of this project is to implement the following models for the CIFAR100 image classification dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u-hdsQCOjF8"
      },
      "source": [
        "### Importing packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqKvuMOvPVgo"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4DYSrBqPYGV"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RSfrtKYYfWm",
        "outputId": "1fe2f865-6dc9-477d-a696-8348574f925d"
      },
      "source": [
        "(train_img, train_label), (test_img, test_label) = cifar100.load_data()\n",
        "\n",
        "train_img = train_img.astype('float32')\n",
        "test_img = test_img.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "train_img = train_img / 255\n",
        "test_img = test_img / 255"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oivf0DssOjGE"
      },
      "source": [
        "###  Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "X-sPYR9sOjGF"
      },
      "source": [
        "batch_size = 50\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 100\n",
        "no_epochs = 25\n",
        "optimizer = Adam()\n",
        "validation_split = 0.1\n",
        "verbosity = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Iopu5yZd09"
      },
      "source": [
        "## Training CNN for CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nab-y7IaI2f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32,32,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(no_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYHgAO4Qbxdc"
      },
      "source": [
        "### Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GypCNf5Obysn"
      },
      "source": [
        "model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjfLW20PasaS"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DReRBpjatbG",
        "outputId": "9167601b-49f8-480f-eff0-d3aff934f57e"
      },
      "source": [
        "history = model.fit(train_img, train_label,\n",
        "            batch_size=batch_size,\n",
        "            epochs=20,\n",
        "            verbose=verbosity,\n",
        "            validation_split=validation_split)\n",
        "score = model.evaluate(test_img, test_label, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "900/900 [==============================] - 111s 123ms/step - loss: 3.8880 - accuracy: 0.1044 - val_loss: 3.4229 - val_accuracy: 0.1704\n",
            "Epoch 2/20\n",
            "900/900 [==============================] - 111s 123ms/step - loss: 3.1106 - accuracy: 0.2322 - val_loss: 2.9982 - val_accuracy: 0.2492\n",
            "Epoch 3/20\n",
            "900/900 [==============================] - 113s 125ms/step - loss: 2.7159 - accuracy: 0.3125 - val_loss: 2.7487 - val_accuracy: 0.3040\n",
            "Epoch 4/20\n",
            "900/900 [==============================] - 110s 123ms/step - loss: 2.4386 - accuracy: 0.3683 - val_loss: 2.5973 - val_accuracy: 0.3452\n",
            "Epoch 5/20\n",
            "900/900 [==============================] - 112s 124ms/step - loss: 2.2170 - accuracy: 0.4159 - val_loss: 2.5310 - val_accuracy: 0.3572\n",
            "Epoch 6/20\n",
            "900/900 [==============================] - 111s 124ms/step - loss: 2.0141 - accuracy: 0.4612 - val_loss: 2.5307 - val_accuracy: 0.3544\n",
            "Epoch 7/20\n",
            "900/900 [==============================] - 111s 123ms/step - loss: 1.8420 - accuracy: 0.4992 - val_loss: 2.5153 - val_accuracy: 0.3786\n",
            "Epoch 8/20\n",
            "900/900 [==============================] - 112s 125ms/step - loss: 1.6723 - accuracy: 0.5377 - val_loss: 2.5547 - val_accuracy: 0.3716\n",
            "Epoch 9/20\n",
            "900/900 [==============================] - 111s 123ms/step - loss: 1.5199 - accuracy: 0.5728 - val_loss: 2.6205 - val_accuracy: 0.3836\n",
            "Epoch 10/20\n",
            "900/900 [==============================] - 110s 122ms/step - loss: 1.3711 - accuracy: 0.6113 - val_loss: 2.7416 - val_accuracy: 0.3814\n",
            "Epoch 11/20\n",
            "900/900 [==============================] - 111s 124ms/step - loss: 1.2217 - accuracy: 0.6491 - val_loss: 2.8351 - val_accuracy: 0.3654\n",
            "Epoch 12/20\n",
            "900/900 [==============================] - 110s 122ms/step - loss: 1.0946 - accuracy: 0.6788 - val_loss: 3.0353 - val_accuracy: 0.3664\n",
            "Epoch 13/20\n",
            "900/900 [==============================] - 110s 122ms/step - loss: 0.9788 - accuracy: 0.7079 - val_loss: 3.1733 - val_accuracy: 0.3654\n",
            "Epoch 14/20\n",
            "900/900 [==============================] - 110s 123ms/step - loss: 0.8585 - accuracy: 0.7407 - val_loss: 3.4228 - val_accuracy: 0.3668\n",
            "Epoch 15/20\n",
            "900/900 [==============================] - 109s 121ms/step - loss: 0.7639 - accuracy: 0.7676 - val_loss: 3.6926 - val_accuracy: 0.3564\n",
            "Epoch 16/20\n",
            "900/900 [==============================] - 110s 123ms/step - loss: 0.6866 - accuracy: 0.7889 - val_loss: 3.8048 - val_accuracy: 0.3586\n",
            "Epoch 17/20\n",
            "900/900 [==============================] - 110s 122ms/step - loss: 0.6015 - accuracy: 0.8114 - val_loss: 4.1849 - val_accuracy: 0.3542\n",
            "Epoch 18/20\n",
            "900/900 [==============================] - 108s 120ms/step - loss: 0.5483 - accuracy: 0.8247 - val_loss: 4.4632 - val_accuracy: 0.3606\n",
            "Epoch 19/20\n",
            "900/900 [==============================] - 108s 120ms/step - loss: 0.4964 - accuracy: 0.8407 - val_loss: 4.6559 - val_accuracy: 0.3530\n",
            "Epoch 20/20\n",
            "900/900 [==============================] - 109s 121ms/step - loss: 0.4449 - accuracy: 0.8571 - val_loss: 4.8516 - val_accuracy: 0.3524\n",
            "Test loss: 4.68107795715332 / Test accuracy: 0.36169999837875366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luW6EmxtOOAy"
      },
      "source": [
        "PS: Actually, the first model I trained has ~93% training and ~30% validation accuracy. So, it was clearly overfitting. I've changed the parameters like validation_split, batch_size and also I've added padding. \r\n",
        "\r\n",
        "The model above has ~85% training and ~36% validation accuracy after this tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1EyKd5DcOHw"
      },
      "source": [
        "### Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD_wilQPcLKW"
      },
      "source": [
        "model.save_weights(\"CIFAR-100_CNN.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9kWAvK_b84P"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKk6SIOObg-P"
      },
      "source": [
        "### Further Fun\n",
        "\n",
        "\n",
        "\n",
        "*   Experiment with different model architectures\n",
        "*   Play with different parameters such as convolution size, pooling, padding, striding, epochs, dropout etc.\n",
        "*   Train a Dense Neural Network as baseline and compare the performance\n",
        "\n"
      ]
    }
  ]
}